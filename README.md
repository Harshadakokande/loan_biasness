

# ğŸ§  **Loan Bias Detection Using Machine Learning & Fairness Metrics**

A complete machine learning project designed to **detect, measure, and reduce bias** in loan approval decisions.
This project identifies whether **protected groups (e.g., gender)** are treated unfairly and applies **fairness mitigation techniques** to correct discrimination.

---

## ğŸ“Œ **Project Overview**

Loan datasets often contain **hidden bias**, leading to unequal treatment of applicants.
For example:

* One gender may receive loans more often
* One group may face higher rejection rates
* Models trained on biased data may continue the discrimination

This project provides an end-to-end solution to **detect**, **measure**, and **mitigate** such bias using:

* **Machine Learning (Logistic Regression)**
* **AIF360 Fairness Toolkit**
* **Fairness Metrics** (Disparate Impact, Equal Opportunity, Demographic Parity)
* **Reweighing Technique** (to reduce bias)

All code is **Google Colabâ€“friendly** and easily reproducible.

---

## ğŸ¯ **Objectives**

âœ” Detect whether loan approval decisions are biased
âœ” Measure fairness using statistical fairness metrics
âœ” Train a baseline ML model and analyze its fairness
âœ” Apply bias mitigation techniques
âœ” Compare model performance before and after fairness correction
âœ” Provide a clean, interpretable conclusion

---

## âš™ï¸ **Technologies Used**

| Category             | Tools / Libraries   |
| -------------------- | ------------------- |
| **Language**         | Python              |
| **ML**               | Scikit-Learn        |
| **Fairness Toolkit** | IBM AIF360          |
| **Visualization**    | Matplotlib, Seaborn |
| **Data Processing**  | Pandas, NumPy       |
| **Environment**      | Google Colab        |

---

## ğŸ“‚ **Project Structure**

```
ğŸ“¦ Loan-Bias-Detection
 â”£ ğŸ“„ loan.csv
 â”£ ğŸ“„ loan_bias_analysis.ipynb
 â”£ ğŸ“„ README.md
 â”— ğŸ“„ requirements.txt
```

---

# ğŸš€ **How to Run the Project (Google Colab)**

### **1ï¸âƒ£ Upload the dataset**

Upload `loan.csv` to Colab or mount Google Drive.

```python
import pandas as pd
df = pd.read_csv("loan.csv")
```

---

### **2ï¸âƒ£ Preprocess the data**

* Handle missing values
* Encode categorical columns
* Scale numeric features

---

### **3ï¸âƒ£ Define sensitive attribute**

Example:

```python
sensitive = "Gender"
label = "Loan_Status"
```

---

### **4ï¸âƒ£ Train logistic regression model**

```python
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
```

---

### **5ï¸âƒ£ Convert dataset to AIF360 format**

Handles fairness metrics and protected attributes.

---

### **6ï¸âƒ£ Calculate fairness metrics**

* **Disparate Impact**
* **Demographic Parity**
* **Equal Opportunity Difference**
* **Average Odds Difference**

These metrics show **how differently each gender is treated**.

---

### **7ï¸âƒ£ Apply Bias Mitigation (Reweighing)**

IBMâ€™s AIF360 Reweighing balances sample weights to remove discrimination.

```python
RW = Reweighing(privileged_groups=[{sensitive:1}],
                unprivileged_groups=[{sensitive:0}])

train_transformed = RW.fit_transform(train_bds)
```

---

### **8ï¸âƒ£ Re-train fair model & compare results**

You will see:

* Improved fairness
* Reduced bias
* Minimal accuracy loss (ideally)

---

### **9ï¸âƒ£ Loan Approval % by Gender**

The project calculates:

* Actual approval rates (Male vs Female)
* Bias gap in approval
* Whether bias is statistically significant

---

# ğŸ“ **Why Was This Project Needed?**

Loan decision-making systems directly impact peopleâ€™s lives.
If the data used to train models contains bias, AI can become discriminatory.

This project helps solve these practical issues:

### âœ” Identify unfair treatment in loan approvals

### âœ” Ensure ML models do not continue discrimination

### âœ” Provide transparency in AI decision-making

### âœ” Help financial institutions maintain ethical & legal compliance

---

# ğŸ”§ **How This Project Solves the Problem**

### âœ… Detects Bias

Uses statistical and ML-based fairness metrics
(e.g., Disparate Impact, Equal Opportunity).

### âœ… Explains Bias

Shows which gender gets higher approval and why.

### âœ… Fixes Bias

Applies **Reweighing** to correct dataset imbalance.

### âœ… Validates Improvement

Compares fairness metrics **before and after** mitigation.

### Result:

A **fairer**, **more ethical**, and **more reliable** loan approval system.

---

# ğŸ“Š **Final Output & Interpretation**

The notebook automatically prints:

* Loan approval percentage for each gender
* Bias gap (in %)
* Whether the dataset is biased
* Fairness metrics before and after correction
* Final, readable conclusion

Example:

```
âš ï¸ Approval gap = 18.5% â†’ High bias
âš ï¸ Disparate Impact = 0.67 â†’ Discrimination detected
âœ“ After Reweighing, Disparate Impact = 0.95 â†’ Bias reduced
```

---

# ğŸ¤ **Contributions**

Feel free to open issues, suggest improvements, or contribute new fairness techniques.

---

# ğŸ“œ **License**

This project is released under the **MIT License**.

---

# ğŸ™Œ **Acknowledgments**

Thanks to **IBM AIF360** and the open-source community for fairness tools.

---


